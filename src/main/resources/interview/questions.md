##各种问题



### 三次握手

### mysql 索引

面试官：那你知道最左前缀匹配吗？我：（我突然想起来原来面试官是想问这个，怪自己刚刚为什么就没想到这个呢。）哦哦哦。您刚刚问的是这个意思啊，在创建多列索引时，我们根据业务需求，where子句中使用最频繁的一列放在最左边，因为MySQL索引查询会遵循最左前缀匹配的原则，即最左优先，在检索数据时从联合索引的最左边开始匹配。所以当我们创建一个联合索引的时候，如(key1,key2,key3)，相当于创建了（key1）、(key1,key2)和(key1,key2,key3)三个索引，这就是最左匹配原则。
建造索引时候会有默认排序，与最长使用的排序方式保持一致。


作者：蛙课网
链接：https://zhuanlan.zhihu.com/p/78982303
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

Index Condition Pushdown（索引下推） MySQL 5.6引入了索引下推优化，默认开启，使用SET optimizer_switch = ‘index_condition_pushdown=off’;可以将其关闭。官方文档中给的例子和解释如下： people表中（zipcode，lastname，firstname）构成一个索引SELECT * FROM people WHERE zipcode=‘95054’ AND lastname LIKE ‘%etrunia%’ AND address LIKE ‘%Main Street%’;如果没有使用索引下推技术，则MySQL会通过zipcode='95054’从存储引擎中查询对应的数据，返回到MySQL服务端，然后MySQL服务端基于lastname LIKE '%etrunia%'和address LIKE '%Main Street%'来判断数据是否符合条件。 如果使用了索引下推技术，则MYSQL首先会返回符合zipcode='95054’的索引，然后根据lastname LIKE '%etrunia%'和address LIKE '%Main Street%'来判断索引是否符合条件。如果符合条件，则根据该索引来定位对应的数据，如果不符合，则直接reject掉。 有了索引下推优化，可以在有like条件查询的情况下，减少回表次数。


面试官：那什么情况下会发生明明创建了索引，但是执行的时候并没有通过索引呢？我：（依稀记得和优化器有关，但是这个问题并没有回答好）科普时间——查询优化器 一条SQL语句的查询，可以有不同的执行方案，至于最终选择哪种方案，需要通过优化器进行选择，选择执行成本最低的方案。 在一条单表查询语句真正执行之前，MySQL的查询优化器会找出执行该语句所有可能使用的方案，对比之后找出成本最低的方案。这个成本最低的方案就是所谓的执行计划。 优化过程大致如下： 1、根据搜索条件，找出所有可能使用的索引 2、计算全表扫描的代价 3、计算使用不同索引执行查询的代价 4、对比各种执行方案的代价，找出成本最低的那一个

Hash和B+有什么区别
hash索引
1:hash索引进行等值查询更快(一般情况下)但是却无法进行范围查询.因为在hash索引中经过hash函数建立索引之后,索引的顺序与原顺序无法保持一致,不能支持范围查询.

2:hash索引不支持模糊查询以及多列索引的最左前缀匹配,因为hash函数的不可预测,eg:AAAA和AAAAB的索引没有相关性.

3:hash索引任何时候都避免不了回表查询数据.

4:hash索引虽然在等值上查询叫快,但是不稳定,性能不可预测,当某个键值存在大量重复的时候,发生hash碰撞,此时查询效率可能极差.

5:hash索引不支持使用索引进行排序,因为hash函数的不可预测.

B+树
1:B+树的所有节点皆遵循(左节点小于父节点,右节点大于父节点,多叉树也类似)自然支持范围查询.

2:在符合某些条件(聚簇索引,覆盖索引等)的时候可以只通过索引完成查询.不需要回表查询.

3:查询效率比较稳定,对于查询都是从根节点到叶子节点,且树的高度较低.

结论
大多数情况下,直接选择B+树索引可以获得稳定且较好的查询速度,而不需要使用Hash索引.

你们线上数据的事务隔离级别是什么呀

索引失效的场景
like以%开头;
where中索引列有运算;
where中索引列使用了函数;
如果mysql优化器觉得全表扫描更快时（数据少）;

隔离级别：
Repeatable Read（可重读）
它确保同一事务的多个实例在并发读取数据时，会看到同样的数据行。不过理论上，这会导致另一个棘手的问题：幻读 （Phantom Read）。

简单的说，幻读指当用户读取某一范围的数据行时，另一个事务又在该范围内插入了新行，当用户再读取该范围的数据行时，会发现有新的“幻影” 行。InnoDB和Falcon存储引擎通过多版本并发控制（MVCC，Multiversion Concurrency Control）机制解决了该问题。

禁止多表join
从优化器的角度而言，选择连接路径的算法目前比较主流的是动态规划和贪心算法，在连接表数比较少的时候选择动态规划，一阶段一阶段的去分析各种可能得连接顺序得到一个最优的执行计划，但动态规划场景下，随表的增加，计划也会爆炸式增加，优化器在选择最优计划的前提下，消耗的内存和CPU是不能不考虑的，所以当表的数量太多，数据库会退化成贪心算法，尽快，尽量少的消耗计算资源前提下出一个计划，这个计划可能不是执行最优的计划。OB的规定是10表以上的星型连接就使用贪心算法，PG还在学术角度实现了基因算法，但工程上，大家很少使用这个。

表设计
表字段避免null值出现，null值很难查询优化且占用额外的索引空间，推荐默认数字0代替null。 尽量使用INT而非BIGINT，如果非负则加上UNSIGNED（这样数值容量会扩大一倍），当然能使用TINYINT、SMALLINT、MEDIUM_INT更好。 使用枚举或整数代替字符串类型 尽量使用TIMESTAMP而非DATETIME 单表不要有太多字段，建议在20以内 用整型来存IP


也就是说第一层的页，即根页（page:3）可以存放1170个指针，然后第二层的每个页（page:4,5,6,7）也可以存放1170个指针。这样一共可以存放1170*1170个指针，所以一共可以存放1170*1170*16=21902400行记录。也就是说一个三层的B+树就可以存放千万级别的数据了。而每经过一个节点都需要IO一次，把这个页数据从磁盘读取到缓存，也就是说读取一个数据只需要三次IO



MVCC的意思用简单的话讲就是对数据库的任何修改的提交都不会直接覆盖之前的数据，而是产生一个新的版本与老版本共存，使得读取时可以完全不加锁。这样读某一个数据时，事务可以根据隔离级别选择要读取哪个版本的数据。过程中完全不需要加锁。

如果事务B是Read Committed。那么就读取X的最新commit的版本，也就是X=2
如果事务B是Repeatable Read。那么读取的就是当前事务（txnId=101）之前X的最新版本，也就是X被txnId=100提交的版本，即X=1。


### es选举算法

Elasticsearch编号比较的判断依据有两个，首先是ClusterState版本号的比较，版本号越大优先级越高，然后是节点id的比较，id越小优先级越高。ClusterState是Master向集群中各个节点发送的集群状态，这个状态有一个版本号码，如果集群状态发生了变化，比如集群新增了节点成员或者有节点成员退出了，那么这个版本号就会加一，比对这个版本号的目的是让拥有最新状态的节点成为Master的优先级最高。

可以处理like类似的查询

es做了大量的缓存，性能更快。


### jvm

gc-root引用链


tomcat 需要维持多个独立的服务

双亲委派模型要求除了顶层的启动类加载器之外，其余的类加载器都应当由自己的父类加载器加载。
而tomcat的webclassloader，不给父加载器加载，它只加载自己的目录下的class文件，不会传递给父类加载器。。这不就违背了吗？？

采用双亲委派模式的是好处是Java类随着它的类加载器一起具备了一种带有优先级的层次关系,通过这种层级关可以避免类的重复加载,当父亲已经加载了该类时,就没有必要子ClassLoader再加载一次。其次是考虑到安全因素,java核心api中定义类型不会被随意替换

新生代采用标记复制算法回收，老年代采用cms算法回收。如果survive空间中相同年龄对象大小综合大于suvivor空间的一半，年龄大于该年龄的对象就可以直接进入老年代。
在 CMS 启动过程中，新生代提升速度过快，老年代收集速度赶不上新生代提升速度
在 CMS 启动过程中，老年代碎片化严重，无法容纳新生代提升上来的大对象



### redis持久化策略
解决缓存不一致的问题
mysql防止断电防止数据丢失

redis 快照+追加
修改同步策略：appendfsync always

击穿: 指的是单个key在缓存中查不到，去数据库查询

雪崩指的是多个key查询并且出现高并发，缓存中失效或者查不到，然后都去db查询，从而导致db压力突然飙升，从而崩溃。

出现原因: 1 key同时失效 2 redis本身崩溃了

布隆过滤器可以理解为一个不怎么精确的 set 结构，当你使用它的 contains 方法判断某个对象是否存在时，它可能会误判。但是布隆过滤器也不是特别不精确，只要参数设置的合理，它的精确度可以控制的相对足够精确，只会有小小的误判概率。 BloomFilter的关键在于hash算法的设定和bit数组的大小确定，通过权衡得到一个错误概率可以接受的结果

我们只需要将这个新的数据通过上面自定义的几个哈希函数，分别算出各个值，然后看其对应的地方是否都是1，如果存在一个不是1的情况，那么我们可以说，该新数据一定不存在于这个布隆过滤器中

RedissonClient redisson = Redisson.create(config);
16 
17         RBloomFilter<String> bloomFilter = redisson.getBloomFilter("phoneList");
18         //初始化布隆过滤器：预计元素为100000000L,误差率为3%
19         bloomFilter.tryInit(100000000L,0.03);
20         //将号码10086插入到布隆过滤器中
21         bloomFilter.add("10086");

跳表
高层级的节点相当于一个快速通道，让搜索进行了节点的跳跃，而不是一个个的遍历

复杂度o(lgn)


公司需要将快销品、调味品转运或销售线下门店、经销商、合作伙伴比如大中小型超市，这些工作都需要线下业务员完成，一个业务员负责一片区域，需要超市举办活动、推销、缺货补货，经销商补充订单。常年下来主要形成了几大区块，比如北京一带、山东一带、江浙沪一带。这些地方的数据各自独立，采用不同的系统和设备。公司希望将全国的数据集中，更好地研发产品、提升业绩。
sfa 项目 包含 本品竞品管理、经销商管理、门店管理、活动核销管理。比如本品竞品管理，会记录销售的商品的各种情况，以及竞品海天、李锦记这的销售产品和大致销量，也有类似地推的扫街功能。形成统一的销量数据、商品数据。也可以提升业务员的积极性和更好的激励制度。每个业务员会负责所辖区域，每日要进店离店需要添加拜访记录并对货架、陈列、门头进行拍照，借助第三方ai图片识别，检测货架摆放是否合理，业务员是否在正确的门店停留。同时根据业务员长期的访店记录，借助第三方实现智能路线规划，为业务员划分合理的管辖区域和拜访门店的路线以及交通工具。
aio项目是 根据 sfa记录下的门店信息，形成门店画像，包括门店的店内装潢、面积、附近的小区、房价等等，形成门店画像。相应的分配区域活动规划和预算。激励规则模块根据不同的区域和门店信息制定各种激励目标。智慧选店根据经销商的区域、规模等等分配门店和协助的业务员。人车管理，处理流动摊位，快销品活动等。


最大的成就：
sfa项目从0-1做起来，在公司互联网转型的当口，从单体服务多节点部署，升级到spring-cloud服务，又放弃注册中心，用aws 的服务，那一年加了很多班，年底拿了最佳员工，还是比较有成就感。

最大的困难：
技术上，都是成熟的技术，开发过程中遇到的困难不多，上线后遇到过一些困难。比如快速开发期间，人员水平参差不齐，上线后慢查询拖垮数据库cpu，临时加索引导致数据库彻底不可用。停服务，让业务员暂时用旧手持，后续手工将数据合并。追加了日志，所有的非查询类接口的请求日志都会完整记录，方便恢复。
人员沟通上的问题。因为项目开发和沟通上涉及多个地方的团队，包括一个全员台湾小伙伴的团队，初期有很多争论。有时候沟通问题要比技术问题难解决得多。

问题：
你们也是用mysql对吗？会进行分库分表吗？表数据量在多大的时候会考虑分库分表？为何不采用nosql？
对于31岁的人来说，你们能看中这个人身上什么特点。因为有些人即使三十多了依然喜欢偏技术。


concurrenthashmap 
只让一个线程对散列表进行初始化 volatile 
在高并发环境下，统计数据(计算size...等等)其实是无意义的，因为在下一时刻size值就变化了。
get方法是非阻塞，无锁的。重写Node类，通过volatile修饰next来实现每次获取都是最新设置的值
futureTask
整体的过程就是这样子的，利用CPU的CAS指令，同时借助JNI来完成Java的非阻塞算法

第一种可能导致Java内存泄漏的场景是用一个静态字段引用一个重对象
第二种是创建一个连接对象后发生异常，对象没有释放
Stream 未关闭



分布式事务

